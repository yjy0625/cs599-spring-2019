{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Generative Adversarial Networks\n",
    "\n",
    "* **Learning Objective:** In this problem, you will implement a Generative Adversarial Network with the network structure proposed in [*Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks*](https://arxiv.org/abs/1511.06434), and learn a visualization technique, *activation maximization*.\n",
    "* **Provided code:** The code for constructing the two parts of the GAN, the discriminator and the generator, is done for you, along with the skeleton code for the training.\n",
    "* **TODOs:** You will need to figure out how to properly feed the data, compute the loss and update the parameters to complete the training and visualization. In addition, to test your understanding, you will answer some non-coding questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: The forger versus the police\n",
    "\n",
    "*Note: read the story even if you are already familiar with GANs, as one of the questions is related to this story.*\n",
    "\n",
    "Generative models try to model the distribution of the data in an explicit way, in the sense that we can easily sample new data points from this model. This is in contrast to discriminative models that try to infer the output from the input. In the class we have seen one classic deep generative model, the Variational Autoencoder (VAE). Here, we will learn another generative model that has risen to prominence in recent years, the Generative Adversarial Network (GAN).\n",
    "\n",
    "As the maths of Generative Adversarial Networks is somewhat tedious, a story is often told of a forger and a police to illustrate the idea.\n",
    "\n",
    "> Imagine a forger that makes fake bills, and a police that tries to find these forgeries. If the forger were a VAE, his goal would be to take some real bills, and try to replicate the real bills as precisely as possible. In GAN, he has a different idea in his mind: rather than trying to replicate the real bills, it suffices to make fake bills such that people *think* they are real.\n",
    "> \n",
    "> Now let's start. In the beginning, the police knows nothing about how to distinguish between real and fake bills. The forger knows nothing either and only produces white paper.\n",
    "> \n",
    "> In the first round, the police gets the fake bill and learns that the forgeries are white while the real bills are green. The forger then finds out that white papers can no longer fool the police and starts to produce green papers.\n",
    ">\n",
    "> In the second round, the police learns that real bills have denominations printed on them while the forgeries do not. The forger then finds out that plain papers can no longer fool the police and starts to print numbers on them.\n",
    ">\n",
    "> In the third round, the police learns that real bills have watermarks on them while the forgeries do not. The forger then has to reproduce the watermarks on his fake bills.\n",
    ">\n",
    "> ...\n",
    ">\n",
    "> Finally, the police is able to spot the tiniest difference between real and fake bills and the forger has to make perfect replicas of real bills to fool the police.\n",
    "\n",
    "Now in a GAN, the forger becomes the generator and the police becomes the discriminator. The discriminator is a binary classifier with the two classes being \"taken from the real data\" (\"real\") and \"generated by the generator\" (\"fake\"). Its objective is to minimize the classification loss. The generator's objective is to generate samples so that the discriminator misclassifies them as real.\n",
    "\n",
    "Here we have some complications: the goal is not to find one perfect fake sample. Such a sample will not actually fool the discriminator: if the forger makes hundreds of the exact same fake bill, they will all have the same serial number and the police will soon find out that they are fake. Instead, we want the generator to be able to generate a variety of fake samples such that when presented as a distribution alongside the distribution of real samples, these two are indistinguishable by the discriminator.\n",
    "\n",
    "So how do we generate different samples with a diterministic generator? We provide it with random numbers as input.\n",
    "\n",
    "Typically, for the discriminator we use binary cross entropy loss with label 1 being real and 0 being fake. For the generator, the input is a random vector drawn from a standard normal distribution. Denote the generator by $G_{\\phi}(z)$, discriminator by $D_{\\theta}(x)$, the distribution of the real samples by $p(x)$ and the input distribution to the generator by $q(z)$. Recall that the binary cross entropy loss with classifier output $y$ and label $\\hat{y}$ is\n",
    "\n",
    "$$L(y, \\hat{y}) = -\\hat{y} \\log y - (1 - \\hat{y}) \\log (1 - y)$$\n",
    "\n",
    "For the discriminator, the objective is\n",
    "\n",
    "$$\\min_{\\theta} \\mathrm{E}_{x \\sim p(x)}[L(D_{\\theta}(x), 1)] + \\mathrm{E}_{z \\sim q(z)}[L(D_{\\theta}(G_{\\phi}(z)), 0)]$$\n",
    "\n",
    "For the generator, the objective is\n",
    "\n",
    "$$\\max_{\\phi} \\mathrm{E}_{z \\sim q(z)}[L(D_{\\theta}(G_{\\phi}(z)), 0)]$$\n",
    "\n",
    "The generator's objective corresponds to maximizing the classification loss of the discriminator on the generated samples. Alternatively, we can **minimize** the classification loss of the discriminator on the generated samples  **when labelled as real**:\n",
    "\n",
    "$$\\min_{\\phi} \\mathrm{E}_{z \\sim q(z)}[L(D_{\\theta}(G_{\\phi}(z)), 1)]$$\n",
    "\n",
    "And this is what we will use in our implementation. The strength of the two networks should be balanced, so we train the two networks alternatingly, updating the parameters in both networks once in each interation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2-1: Implementing the GAN\n",
    "\n",
    "We first load the data (CIFAR-10) and define some convenient functions. You should already have CIFAR-10 from assignment 1. Just copy the data from there or use ```data/get_datasets.sh``` if you don't have them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import sys\n",
    "    if sys.version_info.major == 2:\n",
    "        import cPickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = cPickle.load(fo)\n",
    "        return dict['data'], dict['labels']\n",
    "    else:\n",
    "        import pickle\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict[b'data'], dict[b'labels']\n",
    "\n",
    "def load_train_data():\n",
    "    X = []\n",
    "    for i in range(5):\n",
    "        X_, _ = unpickle('data/cifar-10-batches-py/data_batch_%d' % (i + 1))\n",
    "        X.append(X_)\n",
    "    X = np.concatenate(X)\n",
    "    X = X.reshape((X.shape[0], 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    return X\n",
    "\n",
    "def load_test_data():\n",
    "    X_, _ = unpickle('data/cifar-10-batches-py/test_batch')\n",
    "    X = X_.reshape((X_.shape[0], 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    return X\n",
    "\n",
    "# Load cifar-10 data\n",
    "train_samples = load_train_data() / 255.0\n",
    "test_samples = load_test_data() / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_grid(Xs, padding):\n",
    "    N, H, W, C = Xs.shape\n",
    "    grid_size = int(math.ceil(math.sqrt(N)))\n",
    "    grid_height = H * grid_size + padding * (grid_size + 1)\n",
    "    grid_width = W * grid_size + padding * (grid_size + 1)\n",
    "    grid = np.zeros((grid_height, grid_width, C))\n",
    "    next_idx = 0\n",
    "    y0, y1 = padding, H + padding\n",
    "    for y in range(grid_size):\n",
    "        x0, x1 = padding, W + padding\n",
    "        for x in range(grid_size):\n",
    "            if next_idx < N:\n",
    "                img = Xs[next_idx]\n",
    "                grid[y0:y1, x0:x1] = img\n",
    "                next_idx += 1\n",
    "            x0 += W + padding\n",
    "            x1 += W + padding\n",
    "        y0 += H + padding\n",
    "        y1 += H + padding\n",
    "    return grid\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_random_seed(seed)\n",
    "\n",
    "def conv2d(input, kernel_size, stride, num_filter, name = 'conv2d'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d(input, W, stride_shape, padding = 'SAME') + b\n",
    "\n",
    "def conv2d_transpose(input, kernel_size, stride, num_filter, name = 'conv2d_transpose'):\n",
    "    with tf.variable_scope(name):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, num_filter, input.get_shape()[3]]\n",
    "        output_shape = tf.stack([tf.shape(input)[0], tf.shape(input)[1] * 2, tf.shape(input)[2] * 2, num_filter])\n",
    "\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.nn.conv2d_transpose(input, W, output_shape, stride_shape, padding = 'SAME') + b\n",
    "\n",
    "def fc(input, num_output, name = 'fc'):\n",
    "    with tf.variable_scope(name):\n",
    "        num_input = input.get_shape()[1]\n",
    "        W = tf.get_variable('w', [num_input, num_output], tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        b = tf.get_variable('b', [num_output], initializer = tf.constant_initializer(0.0))\n",
    "        return tf.matmul(input, W) + b\n",
    "\n",
    "def batch_norm(input, is_training):\n",
    "    out = tf.contrib.layers.batch_norm(input, decay = 0.99, center = True, scale = True,\n",
    "                                       is_training = is_training, updates_collections = None)\n",
    "    return out\n",
    "\n",
    "def leaky_relu(input, alpha = 0.2):\n",
    "    return tf.maximum(alpha * input, input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save you some mundane work, we have defined a discriminator and a generator for you, in ```_discriminator()``` and ```_generator()``` respectively. Look at the code to see what layers are there.\n",
    "\n",
    "For this part, you need to complete code blocks marked with \"Prob 2-1\":\n",
    "\n",
    "*   **Build the computation graph for the losses:** Complete the following definitions in ```_init_ops()```\n",
    "    *   ```fake_samples_op```: generate famples from ```noise```\n",
    "    *   ```dis_loss_op```: compute discriminator's loss, with real samples from ```real_input``` and fake\n",
    "        samples generated by the generator\n",
    "    *   ```gen_loss_op```: compute generator's loss\n",
    "*   **Define the optimizer:** We use RMSprop for training. Adam is observed to perform poorly with an unstable objective as is the case in GANs. We've defined ```dis_train_op``` and ```gen_train_op``` for you but those are wrong: rather than updating all the parameters all the time, when training one network we want to keep the other one fixed. Modify the definition to reflect this. [Check here](https://stackoverflow.com/a/35304001) if you are not sure how this is possible.\n",
    "*   **Feed the data:** Feed the proper samples and labels in ```train()``` for training and in ```generate_one_sample()``` for visualizing the generated samples.\n",
    "\n",
    "The batch normalization layers should operate in training mode. As per *[How to Train a GAN? Tips and tricks to make GANs work](https://github.com/soumith/ganhacks)*, we put real samples and fake samples in different batches when training the discriminator.\n",
    "\n",
    "*Note: use the advices on that page with caution if you are doing GAN for your team project. It is already more than 2 years old, which is a **really long time** in deep learning research. It does not reflect the latest results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 5\n",
    "        self.batch_size = 32\n",
    "        self.log_step = 50\n",
    "        self.visualize_step = 200\n",
    "        self.code_size = 64\n",
    "        self.learning_rate = 1e-4\n",
    "        self.vis_learning_rate = 1e-2\n",
    "        self.recon_steps = 100\n",
    "        self.actmax_steps = 100\n",
    "        \n",
    "        self._dis_called = False\n",
    "        self._gen_called = False\n",
    "\n",
    "        self.tracked_noise = np.random.normal(0, 1, [64, self.code_size])\n",
    "\n",
    "        self.real_input = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        self.real_label = tf.placeholder(tf.float32, [None, 1])\n",
    "        self.fake_label = tf.placeholder(tf.float32, [None, 1])\n",
    "        self.noise = tf.placeholder(tf.float32, [None, self.code_size])\n",
    "        \n",
    "        self.is_train = tf.placeholder(tf.bool)\n",
    "        \n",
    "        self.recon_sample = tf.placeholder(tf.float32, [1, 32, 32, 3])\n",
    "        self.actmax_label = tf.placeholder(tf.float32, [1, 1])\n",
    "        \n",
    "        with tf.variable_scope('actmax'):\n",
    "            self.actmax_code = tf.get_variable('actmax_code', [1, self.code_size],\n",
    "                                               initializer = tf.constant_initializer(0.0))\n",
    "        \n",
    "        self._init_ops()\n",
    "\n",
    "    def _discriminator(self, input):\n",
    "        # We have multiple instances of the discriminator in the same computation graph,\n",
    "        # so set variable sharing if this is not the first invocation of this function.\n",
    "        with tf.variable_scope('dis', reuse = self._dis_called):\n",
    "            self._dis_called = True\n",
    "            dis_conv1 = conv2d(input, 4, 2, 32, 'conv1')\n",
    "            dis_lrelu1 = leaky_relu(dis_conv1)\n",
    "            dis_conv2 = conv2d(dis_lrelu1, 4, 2, 64, 'conv2')\n",
    "            dis_batchnorm2 = batch_norm(dis_conv2, self.is_train)\n",
    "            dis_lrelu2 = leaky_relu(dis_batchnorm2)\n",
    "            dis_conv3 = conv2d(dis_lrelu2, 4, 2, 128, 'conv3')\n",
    "            dis_batchnorm3 = batch_norm(dis_conv3, self.is_train)\n",
    "            dis_lrelu3 = leaky_relu(dis_batchnorm3)\n",
    "            dis_reshape3 = tf.reshape(dis_lrelu3, [-1, 4 * 4 * 128])\n",
    "            dis_fc4 = fc(dis_reshape3, 1, 'fc4')\n",
    "            return dis_fc4\n",
    "\n",
    "    def _generator(self, input):\n",
    "        with tf.variable_scope('gen', reuse = self._gen_called):\n",
    "            self._gen_called = True\n",
    "            gen_fc1 = fc(input, 4 * 4 * 128, 'fc1')\n",
    "            gen_reshape1 = tf.reshape(gen_fc1, [-1, 4, 4, 128])\n",
    "            gen_batchnorm1 = batch_norm(gen_reshape1, self.is_train)\n",
    "            gen_lrelu1 = leaky_relu(gen_batchnorm1)\n",
    "            gen_conv2 = conv2d_transpose(gen_lrelu1, 4, 2, 64, 'conv2')\n",
    "            gen_batchnorm2 = batch_norm(gen_conv2, self.is_train)\n",
    "            gen_lrelu2 = leaky_relu(gen_batchnorm2)\n",
    "            gen_conv3 = conv2d_transpose(gen_lrelu2, 4, 2, 32, 'conv3')\n",
    "            gen_batchnorm3 = batch_norm(gen_conv3, self.is_train)\n",
    "            gen_lrelu3 = leaky_relu(gen_batchnorm3)\n",
    "            gen_conv4 = conv2d_transpose(gen_lrelu3, 4, 2, 3, 'conv4')\n",
    "            gen_sigmoid4 = tf.sigmoid(gen_conv4)\n",
    "            return gen_sigmoid4\n",
    "\n",
    "    def _loss(self, labels, logits):\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, logits = logits)\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    def _reconstruction_loss(self, generated, target):\n",
    "        loss = tf.nn.l2_loss(generated - target)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    # Define operations\n",
    "    def _init_ops(self):\n",
    "        \n",
    "        ################################################################################\n",
    "        # Prob 2-1: complete the definition of these operations                        #\n",
    "        ################################################################################\n",
    "        \n",
    "        # self.fake_samples_op = None\n",
    "        # self.dis_loss_op = None\n",
    "        # self.gen_loss_op = None\n",
    "        \n",
    "        ################################################################################\n",
    "        # Prob 2-1: fix the definition of these operations                             #\n",
    "        ################################################################################\n",
    "        \n",
    "        # dis_optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        # self.dis_train_op = dis_optimizer.minimize(self.dis_loss_op)\n",
    "        \n",
    "        # gen_optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        # self.gen_train_op = gen_optimizer.minimize(self.gen_loss_op)\n",
    "        \n",
    "        ################################################################################\n",
    "        # Prob 2-4: check the definition of these operations                           #\n",
    "        # skip this part when working on problem 2-1 and come back for problem 2-4     #\n",
    "        ################################################################################\n",
    "        \n",
    "        self.actmax_sample_op = self._generator(self.actmax_code)\n",
    "        actmax_dis = self._discriminator(self.actmax_sample_op)\n",
    "        self.actmax_loss_op = self._loss(self.actmax_label, actmax_dis)\n",
    "\n",
    "        actmax_optimizer = tf.train.AdamOptimizer(self.vis_learning_rate)\n",
    "        self.actmax_op = actmax_optimizer.minimize(self.actmax_loss_op, var_list = [self.actmax_code])\n",
    "        \n",
    "        ################################################################################\n",
    "        # Prob 2-4: complete the definition of these operations                        #\n",
    "        # skip this part when working on problem 2-1 and come back for problem 2-4     #\n",
    "        ################################################################################\n",
    "        \n",
    "        # self.recon_loss_op = None\n",
    "        \n",
    "        # recon_optimizer = tf.train.AdamOptimizer(self.vis_learning_rate)\n",
    "        # self.reconstruct_op = recon_optimizer.minimize(self.recon_loss_op)\n",
    "        \n",
    "        ################################################################################\n",
    "        #                               END OF YOUR CODE                               #\n",
    "        ################################################################################\n",
    "\n",
    "    # Training function\n",
    "    def train(self, sess, train_samples):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        num_train = train_samples.shape[0]\n",
    "        step = 0\n",
    "        \n",
    "        # smooth the loss curve so that it does not fluctuate too much\n",
    "        smooth_factor = 0.95\n",
    "        plot_dis_s = 0\n",
    "        plot_gen_s = 0\n",
    "        plot_ws = 0\n",
    "        \n",
    "        dis_losses = []\n",
    "        gen_losses = []\n",
    "        max_steps = int(self.num_epoch * (num_train // self.batch_size))\n",
    "        print('Start training ...')\n",
    "        for epoch in range(self.num_epoch):\n",
    "            for i in range(num_train // self.batch_size):\n",
    "                step += 1\n",
    "\n",
    "                batch_samples = train_samples[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "                noise = np.random.normal(0, 1, [self.batch_size, self.code_size])\n",
    "                zeros = np.zeros([self.batch_size, 1])\n",
    "                ones = np.ones([self.batch_size, 1])\n",
    "        \n",
    "                ################################################################################\n",
    "                # Prob 2-1: complete the feed dictionary                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                # dis_feed_dict = {}\n",
    "                \n",
    "                ################################################################################\n",
    "                #                               END OF YOUR CODE                               #\n",
    "                ################################################################################\n",
    "\n",
    "                _, dis_loss = sess.run([self.dis_train_op, self.dis_loss_op], feed_dict = dis_feed_dict)\n",
    "        \n",
    "                ################################################################################\n",
    "                # Prob 2-1: complete the feed dictionary                                       #\n",
    "                ################################################################################\n",
    "                \n",
    "                # gen_feed_dict = {}\n",
    "                \n",
    "                ################################################################################\n",
    "                #                               END OF YOUR CODE                               #\n",
    "                ################################################################################\n",
    "\n",
    "                _, gen_loss = sess.run([self.gen_train_op, self.gen_loss_op], feed_dict = gen_feed_dict)\n",
    "\n",
    "                plot_dis_s = plot_dis_s * smooth_factor + dis_loss * (1 - smooth_factor)\n",
    "                plot_gen_s = plot_gen_s * smooth_factor + gen_loss * (1 - smooth_factor)\n",
    "                plot_ws = plot_ws * smooth_factor + (1 - smooth_factor)\n",
    "                dis_losses.append(plot_dis_s / plot_ws)\n",
    "                gen_losses.append(plot_gen_s / plot_ws)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                    print('Iteration {0}/{1}: dis loss = {2:.4f}, gen loss = {3:.4f}'.format(step, max_steps, dis_loss, gen_loss))\n",
    "\n",
    "            fig = plt.figure(figsize = (8, 8))   \n",
    "            ax1 = plt.subplot(111)\n",
    "            ax1.imshow(viz_grid(self.generate(self.tracked_noise), 1))\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(dis_losses)\n",
    "            plt.title('discriminator loss')\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(gen_losses)\n",
    "            plt.title('generator loss')\n",
    "            plt.xlabel('iterations')\n",
    "            plt.ylabel('loss')\n",
    "            plt.show()\n",
    "        print('... Done!')\n",
    "\n",
    "    # Find the reconstruction of one input sample\n",
    "    def reconstruct_one_sample(self, sample):\n",
    "        \n",
    "        ################################################################################\n",
    "        # Prob 2-4: initialize self.actmax_code                                        #\n",
    "        # skip this part when working on problem 2-1 and come back for problem 2-4     #\n",
    "        ################################################################################\n",
    "        \n",
    "        # actmax_init_val = None\n",
    "        \n",
    "        ################################################################################\n",
    "        #                               END OF YOUR CODE                               #\n",
    "        ################################################################################\n",
    "        \n",
    "        sess.run(self.actmax_code.assign(actmax_init_val))\n",
    "        last_reconstruction = None\n",
    "        last_loss = None\n",
    "        for i in range(self.recon_steps):\n",
    "        \n",
    "            ################################################################################\n",
    "            # Prob 2-4: complete the feed dictionary                                       #\n",
    "            # skip this part when working on problem 2-1 and come back for problem 2-4     #\n",
    "            ################################################################################   \n",
    "            \n",
    "            # recon_feed_dict = {}\n",
    "            \n",
    "            ################################################################################\n",
    "            #                               END OF YOUR CODE                               #\n",
    "            ################################################################################\n",
    "            \n",
    "            run_ops = [self.recon_loss_op, self.reconstruct_op, self.actmax_sample_op]\n",
    "            last_loss, _, last_reconstruction = sess.run(run_ops, feed_dict = recon_feed_dict)\n",
    "        return last_loss, last_reconstruction\n",
    "\n",
    "    # Find the reconstruction of a batch of samples\n",
    "    def reconstruct(self, samples):\n",
    "        reconstructions = np.zeros(samples.shape)\n",
    "        total_loss = 0\n",
    "        for i in range(samples.shape[0]):\n",
    "            loss, reconstructions[i:i+1] = self.reconstruct_one_sample(samples[i:i+1])\n",
    "            total_loss += loss\n",
    "        return total_loss / samples.shape[0], reconstructions\n",
    "\n",
    "    # Generates a single sample from input code\n",
    "    def generate_one_sample(self, code):\n",
    "        \n",
    "        ################################################################################\n",
    "        # Prob 2-1: complete the feed dictionary                                       #\n",
    "        ################################################################################\n",
    "        \n",
    "        # gen_vis_feed_dict = {}\n",
    "        \n",
    "        ################################################################################\n",
    "        #                               END OF YOUR CODE                               #\n",
    "        ################################################################################\n",
    "        \n",
    "        generated = sess.run(self.fake_samples_op, feed_dict = gen_vis_feed_dict)\n",
    "        return generated\n",
    "\n",
    "    # Generates samples from input batch of codes\n",
    "    def generate(self, codes):\n",
    "        generated = np.zeros((codes.shape[0], 32, 32, 3))\n",
    "        for i in range(codes.shape[0]):\n",
    "            generated[i:i+1] = self.generate_one_sample(codes[i:i+1])\n",
    "        return generated\n",
    "\n",
    "    # Perform activation maximization on one initial code\n",
    "    def actmax_one_sample(self, initial_code):\n",
    "        \n",
    "        ################################################################################\n",
    "        # Prob 2-4: check this function                                                #\n",
    "        # skip this part when working on problem 2-1 and come back for problem 2-4     #\n",
    "        ################################################################################\n",
    "        \n",
    "        actmax_init_val = tf.convert_to_tensor(initial_code, dtype = tf.float32)\n",
    "        sess.run(self.actmax_code.assign(actmax_init_val))\n",
    "        for i in range(self.actmax_steps):\n",
    "            actmax_feed_dict = {\n",
    "                self.actmax_label: np.ones([1, 1]),\n",
    "                self.is_train: False\n",
    "            }\n",
    "            _, last_actmax = sess.run([self.actmax_op, self.actmax_sample_op], feed_dict = actmax_feed_dict)\n",
    "        return last_actmax\n",
    "\n",
    "    # Perform activation maximization on a batch of different initial codes\n",
    "    def actmax(self, initial_codes):\n",
    "        actmax_results = np.zeros((initial_codes.shape[0], 32, 32, 3))\n",
    "        for i in range(initial_codes.shape[0]):\n",
    "            actmax_results[i:i+1] = self.actmax_one_sample(initial_codes[i:i+1])\n",
    "        return actmax_results.clip(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the training!\n",
    "\n",
    "Don't panic if the loss curve goes wild. The two networks are competing for the loss curve to go different directions, so virtually anything can happen. If your code is correct, the generated samples should have a high variety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "set_seed(21)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        dcgan = DCGAN()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        dcgan.train(sess, train_samples)\n",
    "        dis_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'dis')\n",
    "        gen_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'gen')\n",
    "        saver = tf.train.Saver(dis_var_list + gen_var_list)\n",
    "        saver.save(sess, 'model/dcgan')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2-2: The forger versus the police, revisited\n",
    "\n",
    "In the forger versus police story, we made part of it hand-wavy to hide a flaw that makes the story improbable to actually happen and makes it a bad analogy of how the training works in a GAN. Now that you have implemented a GAN, can you spot the flaw?\n",
    "\n",
    "Specifically, when we consider one of the two parties, the other is treated as a black box. They know their opponent's result but not how they works. What is wrong here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*The Tao of GANs: They might be adversaries, yet they are also cooperative.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2-3: The Batch Normalization dilemma\n",
    "\n",
    "Here are three questions related to the use of Batch Normalization in GANs. The first two will not be graded and their answers are provided. But you should attempt to solve them before looking at the answer.\n",
    "\n",
    "---\n",
    "\n",
    "We made separate batches for real samples and fake samples when training the discriminator. Is this just an arbitrary design decision made by the inventor that later becomes the common practice, or is it critical to the correctness of the algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select text below to see answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:white;\">When we are training the generator, the input batch to the discriminator will always consist of only fake samples. If we separate real and fake batches when training the discriminator, then the fake samples are normalized in the same way when we are training the discriminator and when we are training the generator. If we mix real and fake samples in the same batch when training the discriminator, then the fake samples are not normalized in the same way when we train the two networks, which causes the generator to fail to learn the correct distribution.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the construction of the discriminator carefully. You will find that between ```dis_conv1``` and ```dis_lrelu1``` there is no batch normalization. This is not a mistake. What could go wrong if there were a batch normalization layer there? Why do you think that omitting this batch normalization layer solves the problem practically if not theoretically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select text below to see answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:white;\">Since we put real samples and fake samples in separate batches, if we add a batch normalization layer between dis_conv1 and dis_lrelu1, the discriminator would not be able to distinguish two distributions if one can be obtained by applying an isotropic scaling and a translation in color space to the other.</p>\n",
    "\n",
    "<p style=\"color:white;\">By removing the first batch normalization layer, for two different distributions to get confused with each other they must produce two distributions after dis_lrelu1 such that one can be obtained by applying an isotropic scaling and a translation to the other. Such a case is still possible but extremely unlikely to happen.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propose a different way of feeding the samples to solve the problem in the second question without omitting any batch normalization layers or changing their mode of operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer below:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Take-aways from this problem: always excercise extreme caution when using batch normalization in your network!*\n",
    "\n",
    "*For further info (optional): you can read this paper to find out more about why Batch Normalization might be bad for your GANs: [On the Effects of Batch and Weight Normalization in Generative Adversarial Networks](https://arxiv.org/abs/1704.03971)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2-4: Activation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Maximization is a visualization technique to see what a particular neuron has learned, by finding the input that maximizes the activation of that neuron. Here we use methods similar to *[Synthesizing the preferred inputs for neurons in neural networks via deep generator networks](https://arxiv.org/abs/1605.09304)*.\n",
    "\n",
    "In short, what we want to do is to find the samples that the discriminator considers most real, among all possible outputs of the generator, which is to say, we want to find the codes (i.e. a point in the input space of the generator) from which the generated images, if labelled as real, would minimize the classification loss of the discriminator:\n",
    "\n",
    "$$\\min_{z} L(D_{\\theta}(G_{\\phi}(z)), 1)$$\n",
    "\n",
    "Compare this to the objective when we were training the generator:\n",
    "\n",
    "$$\\min_{\\phi} \\mathrm{E}_{z \\sim q(z)}[L(D_{\\theta}(G_{\\phi}(z)), 1)]$$\n",
    "\n",
    "The function to minimize is the same, with the difference being that when training the network we fix a set of input data and find the optimal model parameters, while in activation maximization we fix the model parameters and find the optimal input.\n",
    "\n",
    "So, similar to the training, we use gradient descent to solve for the optimal input. Starting from a random code drawn from a standard normal distribution, we perform a fixed step of Adam optimization algorithm on the code.\n",
    "\n",
    "The batch normalization layers should work in evaluation mode.\n",
    "\n",
    "We provide the code for this part, as a reference for solving the next part. You may want to go back to the code above and check the following:\n",
    "\n",
    "*   **Build the computation graph for the loss:** Check the definition of these operations in ```_init_ops()```\n",
    "    *   ```actmax_sample_op```: generate samples from ```actmax_code```\n",
    "    *   ```actmax_loss_op```: compute discriminator's loss on samples generated from ```actmax_code```\n",
    "*   **Define the optimizer:** Check the definition of ```actmax_op```, which updates ```actmax_code```\n",
    "*   **Feed the data:** Check the function ```actmax_one_sample()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "set_seed(241)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        dcgan = DCGAN()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        dis_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'dis')\n",
    "        gen_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'gen')\n",
    "        saver = tf.train.Saver(dis_var_list + gen_var_list)\n",
    "        saver.restore(sess, 'model/dcgan')\n",
    "        actmax_results = dcgan.actmax(np.random.random([64, dcgan.code_size]))\n",
    "        fig = plt.figure(figsize = (8, 8))   \n",
    "        ax1 = plt.subplot(111)\n",
    "        ax1.imshow(viz_grid(actmax_results, 1))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should have less variety than those generated from random code. While it is reasonable that the samples that are \"most real\" makes up only a small portion of the sample space, this also gives us a hint that the so-called \"mode collapse\", in which the GAN simply fails to model a majority part of the data distribution, is a real problem.\n",
    "\n",
    "A similar technique can be used to reconstruct a test sample, that is, to find the code that most closely approximates the test sample. To achieve this, we only need to change the loss function from discriminator's loss to the squared L2-distance between the generated image and the target image:\n",
    "\n",
    "$$\\min_{z} \\left|\\left|G_{\\phi}(z)-x\\right|\\right|_2^2$$\n",
    "\n",
    "This time, we always start from a zero vector.\n",
    "\n",
    "For this part, you need to complete code blocks marked with \"Prob 2-4\":\n",
    "\n",
    "*   **Build the computation graph for the loss:** Complete the definition of ```recon_loss_op``` in ```_init_ops()```, which computes the squared L2-distance between ```recon_sample``` and the sample generated from ```actmax_code```.\n",
    "*   **Define the optimizer:** Modify the definition of ```reconstruct_op``` so that it updates ```actmax_code``` rather than the parameters of the networks.\n",
    "*   **Feed the data:** Set the proper initial value and feed the proper data in ```reconstruct_one_sample()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        dcgan = DCGAN()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        dis_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'dis')\n",
    "        gen_var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'gen')\n",
    "        saver = tf.train.Saver(dis_var_list + gen_var_list)\n",
    "        saver.restore(sess, 'model/dcgan')\n",
    "\n",
    "        avg_loss, reconstructions = dcgan.reconstruct(test_samples[0:64])\n",
    "        print('average reconstruction loss = {0:.4f}'.format(avg_loss))\n",
    "        fig = plt.figure(figsize = (8, 8))   \n",
    "        ax1 = plt.subplot(111)\n",
    "        ax1.imshow(viz_grid(test_samples[0:64], 1))\n",
    "        plt.show()\n",
    "        fig = plt.figure(figsize = (8, 8))   \n",
    "        ax1 = plt.subplot(111)\n",
    "        ax1.imshow(viz_grid(reconstructions, 1))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see the effect of increasing the training epochs. You should be able to achieve a reconstruction loss lower than 32."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
